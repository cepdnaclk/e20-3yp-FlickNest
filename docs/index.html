<!DOCTYPE HTML>
<html>
<head>
    <title>FlickNest - Gesture-Controlled Smart Automation</title>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
    <link rel="stylesheet" href="assets/css/main.css" />
    <noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
</head>
<body class="is-preload">

    <!-- Wrapper -->
    <div id="wrapper" class="fade-in">

        <!-- Intro -->
        <div id="intro">
            <h1>Welcome to<br />
            FlickNest</h1>
            <p>Transforming intuitive hand gestures into commands for controlling smart devices.<br />
            Hands-free, inclusive, and privacy-focused automation.</p>
            <ul class="actions">
                <li><a href="#main" class="button icon solid solo fa-arrow-down scrolly">Learn More</a></li>
            </ul>
        </div>

        <!-- Header -->
        <header id="header">
            <a href="index.html" class="logo">FlickNest</a>
        </header>

        <!-- Nav -->
        <nav id="nav">
            <ul class="links">
                <li class="active"><a href="index.html">Home</a></li>
                <li><a href="generic.html">About</a></li>
                <li><a href="elements.html">Features</a></li>
            </ul>
        </nav>

        <!-- Main -->
        <div id="main">

            <!-- Featured Post -->
            <article class="post featured">
                <header class="major">
                    <h2>FlickNest</h2>
                    <h3> Gesture-Controlled Smart Automation</h3>
                </header>

                <!-- Video Section -->
                <video width="100%" controls>
                    <source src="video/demo.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                </video>

                <!-- Introduction Section -->
                <h2 style="text-align: left;">Introduction</h2>
                <p>
                    FlickNest is a gesture-controlled smart automation system that leverages wearable sensors, machine learning, and cloud services to enable intuitive, hands-free device control. It enhances accessibility, convenience, and efficiency by eliminating dependency on smartphones or voice assistants.
                </p>

                <!-- Problem & Solution -->
                <h2 style="text-align: left;">Problem & Solution</h2>
                <p>
                    Many smart systems lack accessibility for elderly or physically limited users and are impractical in noisy or busy environments. FlickNest solves this with a wearable band featuring an MPU6050 sensor and ESP32 microcontroller, classifying gestures locally using Edge Impulse. Recognized gestures are securely transmitted via MQTT to AWS IoT Core or a local broker, then update Firebase for device state control.
                </p>

                <!-- Impact -->
                <h2 style="text-align: left;">Impact</h2>
                <p>
                    FlickNest provides accessible, efficient smart control:
                    <br>• Hands-free interaction for improved usability.
                    <br>• Real-time secure control of home devices.
                    <br>• Scalable and low-latency response using both cloud and local broker setups.
                </p>

                <ul class="actions special">
                    <li><a href="generic.html" class="button large">Learn More</a></li>
                </ul>
            </article>

            <!-- Posts -->
            <section class="posts">
                <article>
                    <header><h2><a href="#">System Architecture</a></h2></header>
                    <a href="#" class="image fit"><img src="images/system_architecture.jpg" alt="System Architecture" /></a>
                    <p>The system runs TinyML classification on-device (ESP32) and uses MQTT to trigger AWS Lambda and GCP Firebase updates. Flutter UI reflects real-time changes, and smart devices respond instantly. The architecture supports both cloud-based and Raspberry Pi 3-based local brokers for redundancy.</p>
                    <ul class="actions special">
                        <li><a href="generic.html" class="button">Explore</a></li>
                    </ul>
                </article>
                <article>
                    <header><h2><a href="#">Data Flow</a></h2></header>
                    <a href="#" class="image fit"><img src="images/Gesture_Control.png" alt="Gesture Recognition" /></a>
                    <p>MPU6050 captures motion. ESP32 classifies gestures using Edge Impulse, authenticates via fingerprint, and publishes data via MQTT. AWS/GCP process it to update Firebase. Flutter UI reflects device states in real time. Local broker ensures offline functionality.</p>
                    <ul class="actions special">
                        <li><a href="generic.html" class="button">Learn More</a></li>
                    </ul>
                </article>
            </section>

            <!-- Testing Section -->
            <article class="post featured">
                <h2 style="text-align: left;">Testing</h2>
                <p>We conducted comprehensive testing across hardware, software, and cloud components:</p>

                <h3 style="text-align: left;">1. Hardware Testing</h3>
                <p>• Validated MPU6050 sensor responsiveness, gesture accuracy (>90%), and ESP32 stability.
                <br>• Measured latency and ensured consistent response across multiple devices.</p>
                <img src="images\testh.png" alt="Hardware Test" style="max-width: 100%; height: auto;">

                <h3 style="text-align: left;">2. Software & Cloud Testing</h3>
                <p>• Tested Firebase Cloud Function (testFunctions3) integration with AWS IoT Core using <strong>firebase-functions-test</strong>, <strong>sinon</strong>, <strong>chai</strong>, and <strong>proxyquire</strong>.
                <br>• Verified bidirectional MQTT communication from mobile, ESP32, and dashboard to cloud/local brokers.</p>
                <img src="images/tests.png" alt="Software Test" style="max-width: 100%; height: auto;">

                <h3 style="text-align: left;">3. End-to-End Testing</h3>
                <p>• Conducted full-cycle tests using both mobile and wearable inputs.
                <br>• Confirmed real-time state updates across Flutter app, Firebase, and MQTT.
                <br>• Tested redundancy via both AWS IoT Core and local Raspberry Pi broker.</p>
                </ul>
            </article>

            <!-- Deployment Section -->
            <article class="post featured">
            <h2 style="text-align: left;">Deployment</h2>
            <p>
                <img src="images/deployed.png" alt="Software Test" style="max-width: 100%; height: auto;">
                <br>• AWS Lambda functions and Google Cloud Functions were deployed to handle backend processing and updates to Firebase.
                <br>• A Raspberry Pi 3 running a local MQTT broker was integrated for offline/local functionality.
                <br>• The Flutter-based super admin dashboard was deployed to Vercel, providing centralized real-time device monitoring and control.
            </p>
            </article>
        <!-- Copyright -->
        <div id="copyright">
            <ul><li>&copy; FlickNest</li><li>Design: Team Byte Crafters</li></ul>
        </div>

    </div>

    <!-- Scripts -->
    <script src="assets/js/jquery.min.js"></script>
    <script src="assets/js/jquery.scrollex.min.js"></script>
    <script src="assets/js/jquery.scrolly.min.js"></script>
    <script src="assets/js/browser.min.js"></script>
    <script src="assets/js/breakpoints.min.js"></script>
    <script src="assets/js/util.js"></script>
    <script src="assets/js/main.js"></script>

</body>
</html>
